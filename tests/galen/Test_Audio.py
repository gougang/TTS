# from TTS.api import TTS
#
# models = TTS().list_models()
# models_name = models.list_models()[0]
# print(models_name)
# tts = TTS(models_name)
# wav = tts.tts("This is a test! This is also a test!!", speaker=tts.speakers[0], language=tts.languages[0])
# tts.tts_to_file(text="Hello world!", speaker=tts.speakers[0], language=tts.languages[0], file_path="output.wav")
import torch
from TTS.api import TTS

# Get device
device = "cuda" if torch.cuda.is_available() else "mps"
print("mps:", torch.backends.mps.is_available())
# List available ğŸ¸TTS models
models = TTS().list_models()
models_name = models.list_models()[0]
# Init TTS
tts = TTS(model_path="/Users/galen/git/hugginface/XTTS-v2",
          config_path="/Users/galen/git/hugginface/XTTS-v2/config.json")

# Run TTS
# â— Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language
# Text to speech list of amplitude values as output
wav = tts.tts(
    text="è¿™åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½æœ‰åŠ©äºæé«˜æ€§èƒ½æˆ–è§£å†³ä¸€äº›ä¸GPUç›¸å…³çš„é—®é¢˜ã€‚ä½†è¯·æ³¨æ„ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´ä¸€äº›æ€§èƒ½æŸå¤±ï¼Œå› ä¸ºCPUçš„è®¡ç®—é€Ÿåº¦é€šå¸¸æ¯”GPUæ…¢!",
    speaker_wav="/Users/galen/temp/my.wav", language="zh-cn")
# Text to speech to a file
tts.tts_to_file(
    text="è¿™åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½æœ‰åŠ©äºæé«˜æ€§èƒ½æˆ–è§£å†³ä¸€äº›ä¸GPUç›¸å…³çš„é—®é¢˜ã€‚ä½†è¯·æ³¨æ„ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´ä¸€äº›æ€§èƒ½æŸå¤±ï¼Œå› ä¸ºCPUçš„è®¡ç®—é€Ÿåº¦é€šå¸¸æ¯”GPUæ…¢!",
    speaker_wav="/Users/galen/temp/my.wav",
    language="zh-cn",
    file_path="/Users/galen/temp/output.wav")
